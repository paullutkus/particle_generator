{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for evaluation of a trained AutoEncoder Model\n",
    "- This notebook is step 1 of 3 in setting up a model pipeline for generating particle decay event images\n",
    "- The notebook is broken up into the following components:\n",
    "    - Loss evaluation and plotting\n",
    "        - The loss for the entire training cycle is plotted\n",
    "        - The mean and stddev for the loss values for model checkpoints between 600 to 1000.\n",
    "            - We compute the average loss value over 10k test samples and 10k training samples\n",
    "    - An appropriately generalizable Decoder is chosen based on the smalled difference in MSE value from the previous evaluation step\n",
    "    - Sets of sample images are generated for that checkpoint using test data in order to assess image reconstruction quality\n",
    "    - A set of code vector targets is generated using that model checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision      import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Files from full path on Mayer Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/plutku01/projects/particle_generator/')\n",
    "\n",
    "# Mayer Machine\n",
    "import ae\n",
    "import conv_ae\n",
    "import res_ae\n",
    "import utils\n",
    "from dataloader import LArCV_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the GPU to be used for model evaluation\n",
    "- On Meitner, GPU 1 is the best option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which is best on Mayer?\n",
    "device = torch.device(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the root path of the AutoEncoder Experiments Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_root = \"/home/plutku01/projects/particle_generator/experiments/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the model class and append to the experiment root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = {'mlp': 'mlp_ae/', 'conv':'conv_ae/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = False\n",
    "if mnist:\n",
    "    model_folder = 'mnist_ae/'\n",
    "else:\n",
    "    model_folder = \"larcv_ae/\" + model_class['conv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_root += model_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all the experiments in the exp_root folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_paths = []\n",
    "for path in os.listdir(exp_root):\n",
    "    exp_paths.append(os.path.join(exp_root, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\n",
      "0: 07-20-2020_10-49-24_res_ae_100_epochs_LArCV_64_dataset_512_l-dim \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "1: 07-20-2020_11-25-28_conv_ae_200_epochs_LArCV_64_dataset_512_l-dim \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "2: 07-23-2020_11-37-09_conv_ae_100_epochs_LArCV_64_dataset_512_l-dim \n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "3: 07-13-2020_13-56-21_res_ae_100_epochs_LArCV_64_dataset_512_l-dim \n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*60)\n",
    "for i in range(len(exp_paths)):\n",
    "    exp_name = exp_paths[i].split('/')[-1]\n",
    "    print(\"\\n{}:\".format(str(i)), exp_name, '\\n')\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the experiment for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = exp_paths[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment path set as: \n",
      "/home/plutku01/projects/particle_generator/experiments/larcv_ae/conv_ae/07-23-2020_11-37-09_conv_ae_100_epochs_LArCV_64_dataset_512_l-dim/\n"
     ]
    }
   ],
   "source": [
    "# Create the full path to the experiment\n",
    "exp_path = os.path.join(exp_root, exp_dir) + \"/\"\n",
    "print(\"Experiment path set as: \\n{}\".format(exp_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path from where to load the model weights\n",
    "weights_dir = \"weights/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model configuration information from the config.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config csv as a dict\n",
    "config_csv = exp_path + \"config.csv\"\n",
    "config_df = pd.read_csv(config_csv, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model architecture from config df\n",
    "num_epochs = int(config_df[config_df['Unnamed: 0'].str.contains(\"epochs\")==True]['0'].values.item())\n",
    "n_layers = int(config_df[config_df['Unnamed: 0'].str.contains(\"n_layers\")==True]['0'].values.item())\n",
    "l_dim    = int(config_df[config_df['Unnamed: 0'].str.contains(\"l_dim\")==True]['0'].values.item())\n",
    "depth    = int(config_df[config_df['Unnamed: 0'].str.contains(\"depth\")==True]['0'].values.item())\n",
    "im_size  = int(config_df[config_df['Unnamed: 0'].str.contains(\"dataset\")==True]['0'].values.item())**2\n",
    "im_dim   = int(np.sqrt(im_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 64 4096 64\n"
     ]
    }
   ],
   "source": [
    "print(n_layers, depth, im_size, im_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the paths to the test data and reference training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 test data will be loaded from: \n",
      "/home/plutku01/data/LArCV/test/larcv_png_64/\n"
     ]
    }
   ],
   "source": [
    "test_data = \"/home/plutku01/data/LArCV/test/larcv_png_{}/\".format(im_dim)\n",
    "num_test_ex = sum( [len(examples) for _, _, examples in os.walk(test_data)] )\n",
    "print(\"{} test data will be loaded from: \\n{}\".format(num_test_ex, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 reference training data will be loaded from: \n",
      "/home/plutku01/data/LArCV/train/train_reference/larcv_png_64/\n"
     ]
    }
   ],
   "source": [
    "train_data = \"/home/plutku01/data/LArCV/train/train_reference/larcv_png_{}/\".format(im_dim)\n",
    "num_train_ex = sum( [len(examples) for _, _, examples in os.walk(train_data)] )\n",
    "print(\"{} reference training data will be loaded from: \\n{}\".format(num_train_ex, train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup two instances of a dataloader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_kwargs = {'num_workers' : 2, 'batch_size': 1, 'shuffle': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5],[0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image conversion flag is: L\n",
      "Images will be loaded from subfolder of: /home/plutku01/data/LArCV/test/larcv_png_64/\n"
     ]
    }
   ],
   "source": [
    "if mnist:\n",
    "    data_root = \"/home/plutku01/projects/particle_generator/data/\"\n",
    "    test_dataset = datasets.MNIST(root=data_root, train=True, download=False, transform=transforms)\n",
    "else:\n",
    "    test_dataset = LArCV_loader(root = test_data,  transforms = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mnist:\n",
    "    test_loader = DataLoader(test_dataset, **loader_kwargs)\n",
    "else:\n",
    "    test_loader = DataLoader(test_dataset, **loader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image conversion flag is: L\n",
      "Images will be loaded from subfolder of: /home/plutku01/data/LArCV/train/train_reference/larcv_png_64/\n"
     ]
    }
   ],
   "source": [
    "if mnist:\n",
    "    pass\n",
    "else:\n",
    "    train_dataset = LArCV_loader(root = train_data, transforms = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mnist:\n",
    "    pass\n",
    "else:\n",
    "    train_loader = DataLoader(train_dataset, **loader_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the layer dimensions for the AutoEncoder\n",
    "- TODO: Need to add function that deals with an AutoEncoder Model trained on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up AE layer sizes\n",
    "if 'mlp' in exp_path:    \n",
    "    base = [256] \n",
    "\n",
    "    # Compute encoder sizes\n",
    "    sizes = lambda: [ (yield 2**i) for i in range(n_layers) ]\n",
    "    enc_sizes = base * n_layers\n",
    "    enc_sizes = [a*b for a,b in zip(enc_sizes, [*sizes()])][::-1]\n",
    "\n",
    "    # Update kwarg dicts\n",
    "    # Decoder is the reverse of the encoder\n",
    "    ae_kwargs = {'enc_sizes' : enc_sizes, 'l_dim' : l_dim, 'im_size' : im_size, 'dec_sizes' : enc_sizes[::-1]}\n",
    "else:\n",
    "    # Compute the depth of the feature maps, based on the number of\n",
    "    # specified layers. If depth is not divisibe by 4, warn\n",
    "    depth   = [depth] * n_layers\n",
    "    divisor = lambda: [ (yield 2**i) for i in range(n_layers) ]\n",
    "    depth   = [a//b for a,b in zip(depth, [*divisor()])][::-1]\n",
    "        \n",
    "    # Update kwarg dicts\n",
    "    # Decoder is the reverse of the encoder\n",
    "    ae_kwargs = {'enc_depth':[1] + depth, 'dec_depth':depth[1:len(depth)][::-1] + [1],'l_dim':l_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model l_dim: 512\n",
      "Encoder depth: [1, 8, 16, 32, 64]\n",
      "Decoder depth: [64, 32, 16, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model l_dim: {}\".format(l_dim))\n",
    "print(\"Encoder depth: {}\".format(ae_kwargs['enc_depth']))\n",
    "print(\"Decoder depth: {}\".format(ae_kwargs['dec_depth']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Model loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up tracking of MSE evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_means = []; test_stds = []; train_means = []; train_stds = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model from Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the list of checkpoint files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path  = exp_path + weights_dir\n",
    "checkpoint_names = []\n",
    "for file in os.listdir(checkpoint_path):\n",
    "    checkpoint_names.append(os.path.join(checkpoint_path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wish to save a list of labels for ease of plot labelling later\n",
    "checkpoint_name_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "\n",
      "0: best_conv_ae_ep_99.tar \n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*60)\n",
    "for i in range(len(checkpoint_names)):\n",
    "    name = checkpoint_names[i].split('/')[-1]\n",
    "    checkpoint_name_labels.append(name)\n",
    "    print(\"\\n{}:\".format(str(i)), name, '\\n')\n",
    "    print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the checkpoint you wish to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, 0, 3, 7, 8, 4, 5, 6, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "current_checkpoint = checkpoint_names[index]\n",
    "current_checkpoint_label = checkpoint_name_labels[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the checkpoint file using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model checkpoint\n",
    "# Keys: ['state_dict', 'epoch', 'optimizer']\n",
    "checkpoint = torch.load(current_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the model on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model on GPU\n",
    "if 'mlp' in exp_path:\n",
    "    model = ae.AutoEncoder(**ae_kwargs).to(device)\n",
    "else:\n",
    "    model = conv_ae.ConvAutoEncoder(**ae_kwargs).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model's state dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ConvAutoEncoder:\n\tsize mismatch for decoder.deconv_blocks.2.2.weight: copying a param with shape torch.Size([4, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 16, 3, 3]).\n\tsize mismatch for decoder.deconv_blocks.2.2.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4095f9f1909f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 845\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ConvAutoEncoder:\n\tsize mismatch for decoder.deconv_blocks.2.2.weight: copying a param with shape torch.Size([4, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([1, 16, 3, 3]).\n\tsize mismatch for decoder.deconv_blocks.2.2.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([1])."
     ]
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put model in evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If evaluating convolutional model, get the size of the code tensor using a random torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'conv' in exp_path:\n",
    "    code = (l_dim)\n",
    "    '''\n",
    "    x = torch.randn(1, 1, im_dim, im_dim).to(device)\n",
    "    x = model.encoder(x)\n",
    "    code = (x.shape[1], x.shape[2], x.shape[3])\n",
    "    print(\"Code tensor volume is: [{} x {} x {}] = {}\".format(code[0], code[1], code[2], code[0]*code[1]*code[2]))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model Loss Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full loss curve for entire training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_csv = exp_path + \"losses.csv\"\n",
    "losses_df = pd.read_csv(losses_csv, delimiter = \",\")\n",
    "losses = np.asarray(losses_df['ae_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average loss per epoch based based on loss array len\n",
    "step = int(len(losses) / num_epochs)\n",
    "new_losses = []\n",
    "for i in range(0, len(losses), step):\n",
    "    new_losses.append( sum(losses[i:i+step]) / step )\n",
    "new_losses = np.asarray(new_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the label for the checkpoint being evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_label = current_checkpoint_label.split('.')[0].split('_')[-1]\n",
    "test_label = 'test_ep_{}'.format(checkpoint_label)\n",
    "train_label = 'train_ep_{}'.format(checkpoint_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoint_label, test_label, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss values for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses = []; test_ims = []; samples = []; limit = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, image in enumerate(test_loader):\n",
    "    \n",
    "    # Flatten image into a vector -- if mlp\n",
    "    if 'mlp' in exp_path:\n",
    "        image = image.view(loader_kwargs['batch_size'], -1).to(device)\n",
    "    else:\n",
    "        image = image.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(image)\n",
    "    \n",
    "    # Save list of samples for plotting later\n",
    "    if idx < limit:\n",
    "        # Concatenate the two images along the channel dimension and append to list\n",
    "        # For later plotting with MatPlotLib below this cell\n",
    "        test_ims.append(image.view(-1, im_dim, im_dim).detach().cpu().numpy())\n",
    "        samples.append(output.view(-1, im_dim, im_dim).detach().cpu().numpy())\n",
    "\n",
    "    # Get the loss value for the batch\n",
    "    loss = loss_fn(output, image)\n",
    "    \n",
    "    # Append loss value\n",
    "    test_losses.append(float(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the mean and stddev for the checkpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mean = np.mean(test_losses)\n",
    "test_std  = np.std(test_losses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_means.append(test_mean)\n",
    "test_stds.append(test_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss values for reference-train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, image in enumerate(train_loader):    \n",
    "\n",
    "    # Flatten image into a vector\n",
    "    if 'mlp' in exp_path:\n",
    "        image = image.view(loader_kwargs['batch_size'], -1).to(device)\n",
    "    else:\n",
    "        image = image.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(image)\n",
    "    \n",
    "    # Get the loss value for the batch\n",
    "    loss = loss_fn(output, image)\n",
    "    \n",
    "    # Append loss value\n",
    "    ref_train_losses.append(float(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(ref_train_losses)\n",
    "train_std  = np.std(ref_train_losses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_means.append(train_mean)\n",
    "train_stds.append(train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Free the GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a set of sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Setup figure\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = limit//2, sharex=True, sharey=True, figsize=(25,6))\n",
    "\n",
    "# Set title\n",
    "if 'mlp' in exp_path:\n",
    "    m_label = 'AE_test_set_checkpoint_{}'.format(checkpoint_label)\n",
    "else:\n",
    "    m_label = 'Conv_AE_test_set_checkpoint_{}'.format(checkpoint_label)\n",
    "\n",
    "# Generate plot\n",
    "for images, row in zip([test_ims, samples], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        img = np.reshape(img, (im_dim, im_dim))\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        ax.tick_params(axis='x', colors='#443941')\n",
    "        ax.tick_params(axis='y', colors='#443941')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "save_file = \"{}_{}_{}.png\".format(m_label, im_dim, code)# code[0]*code[1]*code[2])\n",
    "plt.savefig(save_file, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Full Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the plot title\n",
    "if 'mlp' in exp_path:\n",
    "    title = \"MLP AutoEncoder Training Loss\" \n",
    "else:\n",
    "    title = \"Convolutional AutoEncoder Training Loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the experiment label\n",
    "if 'mlp' in exp_path:\n",
    "    label = \"{}x{} Dataset | {} Dimensional Code Vector\".format(im_dim, im_dim, l_dim)\n",
    "else:\n",
    "    label = \"{}x{} Dataset | {} Dimensional Code Vector\".format(im_dim, im_dim, code)# [0], code[1], code[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the file name for saving\n",
    "if 'mlp' in exp_path:\n",
    "    save_file = \"training_loss_MLP_AE_{}_dataset_{}_l-dim.png\".format(im_dim, l_dim)\n",
    "else:\n",
    "    save_file = \"training_loss_Conv_AE_{}_dataset_{}_code-vector.png\".format(im_dim, code)# [0], code[1], code[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "checkpoints = [i for i in range(600, 1050, 50)]\n",
    "colors = ['black', 'green', 'magenta', 'gray'] \n",
    "\n",
    "# Train Loss Label\n",
    "l0 = Line2D([0], [0], color='blue', lw=2, label='Train Loss')\n",
    "\n",
    "# Train Legend Labels\n",
    "l1 = Line2D([0], [0], marker='o', color=colors[0], label='Train Mean', markerfacecolor= colors[0], markersize=10)\n",
    "l2 = Line2D([0], [0], color=colors[1], lw=2, label='Train StdDev')\n",
    "\n",
    "# Test Legend Labels\n",
    "l3 = Line2D([0], [0], marker='x', color=colors[2], label='Test Mean', markerfacecolor= colors[2], markersize=10)\n",
    "l4 = Line2D([0], [0], color=colors[3], lw=2, label='Test StdDev')\n",
    "\n",
    "# Create custom legend list\n",
    "legend = [l0, l1, l2, l3, l4]\n",
    "\n",
    "# Plot the losses against the number of epochs\n",
    "fig, axes = plt.subplots(1,1)\n",
    "fig.suptitle(title)\n",
    "\n",
    "axes.set_title(label, fontsize=\"small\")\n",
    "axes.set_xlabel(\"Model Checkpoint Number\")\n",
    "axes.set_ylabel(\"Loss Value\")\n",
    "\n",
    "axes.plot(np.arange(0, num_epochs), new_losses, color = 'b')\n",
    "\n",
    "# Plot data\n",
    "for i in range(len(train_means)):\n",
    "    # Reference Training Set\n",
    "    label = 'train_ep_{}'.format(checkpoints[i])\n",
    "    axes.errorbar(checkpoints[i], train_means[i], yerr=train_stds[i], color=colors[0],\n",
    "                  ecolor = colors[1], label=label, fmt='o')\n",
    "    \n",
    "    # Test Set\n",
    "    label = 'test_ep_{}'.format(checkpoints[i])\n",
    "    axes.errorbar(checkpoints[i], test_means[i],  yerr=test_stds[i], color=colors[2],\n",
    "                  ecolor = colors[3], label=label, fmt='x')\n",
    "\n",
    "axes.legend(handles = legend)\n",
    "\n",
    "# Generate and save image\n",
    "plt.savefig(save_file, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the individual checkpoint results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the plot title\n",
    "if 'mlp' in exp_path:\n",
    "    title = \"MLP AutoEncoder Checkpoint Evaluation\" \n",
    "else:\n",
    "    title = \"Convolutional AutoEncoder Checkpoint Evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the experiment label\n",
    "if 'mlp' in exp_path:\n",
    "    label = \"{}x{} Dataset | {} Dimensional Code Vector\".format(im_dim, im_dim, l_dim)\n",
    "else:\n",
    "    label = \"{}x{} Dataset | {} Dimensional Code Vector\".format(im_dim, im_dim, code)# [0], code[1], code[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the file name for saving\n",
    "if 'mlp' in exp_path:\n",
    "    save_file = \"checkpoint_eval_MLP_AE_{}_dataset_{}_l-dim.png\".format(im_dim, l_dim)\n",
    "else:\n",
    "    save_file = \"checkpoint_eval_Conv_AE_{}_dataset_{}_code-volume.png\".format(im_dim, code)#[0], code[1], code[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "checkpoints = [i for i in range(600, 1050, 50)]\n",
    "colors = ['black', 'green', 'magenta', 'gray'] \n",
    "\n",
    "l0 = Line2D([0], [0], color='blue', lw=2, label='Train Loss')\n",
    "\n",
    "# Train Legend Labels\n",
    "l1 = Line2D([0], [0], marker='o', color=colors[0], label='Train Mean',   markerfacecolor= colors[0], markersize=10)\n",
    "l2 = Line2D([0], [0], color=colors[1], lw=2, label='Train StdDev')\n",
    "\n",
    "# Test Legend Labels\n",
    "l3 = Line2D([0], [0], marker='x', color=colors[2], label='Test Mean',    markerfacecolor= colors[2], markersize=10)\n",
    "l4 = Line2D([0], [0], color=colors[3], lw=2, label='Test StdDev')\n",
    "\n",
    "# Create custom legend list\n",
    "legend = [l0, l1, l2, l3, l4]\n",
    "\n",
    "# Plot the losses against the number of epochs\n",
    "fig, axes = plt.subplots(1,1)\n",
    "fig.suptitle(title)\n",
    "\n",
    "axes.set_title(label, fontsize=\"small\")\n",
    "axes.set_xlabel(\"Model Checkpoint Number\")\n",
    "axes.set_ylabel(\"Loss Value\")\n",
    "\n",
    "axes.plot(np.arange(600, 1000), new_losses[600:])\n",
    "\n",
    "# Plot data\n",
    "for i in range(len(train_means)):\n",
    "    # Reference Training Set\n",
    "    label = 'train_ep_{}'.format(checkpoints[i])\n",
    "    axes.errorbar(checkpoints[i], train_means[i], yerr=train_stds[i], color=colors[0],\n",
    "                  ecolor = colors[1], label=label, fmt='o')\n",
    "    \n",
    "    # Test Set\n",
    "    label = 'test_ep_{}'.format(checkpoints[i])\n",
    "    axes.errorbar(checkpoints[i], test_means[i],  yerr=test_stds[i], color=colors[2],\n",
    "                  ecolor = colors[3], label=label, fmt='x')\n",
    "\n",
    "\n",
    "axes.legend(handles = legend)\n",
    "# Generate and save image\n",
    "plt.savefig(save_file, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Histograms of peak loss regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_count(n):\n",
    "    max_counts = 0; idx = 0\n",
    "    for i in range(len(n)):\n",
    "        if n[i] > max_counts:\n",
    "            max_counts = n[i]\n",
    "            idx = i\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_hist(losses, checkpoint_label, test=False):\n",
    "    n, bins, patches = plt.hist(losses, bins=5000)\n",
    "    if test:\n",
    "        plt.suptitle(\"Test Set Loss Value Distribution\")\n",
    "    else:\n",
    "        plt.suptitle(\"Train Set Loss Value Distribution\")\n",
    "        \n",
    "    plt.title(\"min: {} | max: {}\".format(round(min(losses), 4), round(max(losses), 3)))\n",
    "    plt.xlabel('Loss Value')\n",
    "    plt.ylabel('Counts')\n",
    "\n",
    "    max_count = get_max_count(n)\n",
    "    plt.axvline(x = bins[-1], color = 'r', label = \"max\")\n",
    "    plt.axvline(x = bins[-2], color = 'r', label = \"max\")\n",
    "    plt.axvline(x = bins[-3], color = 'r', label = \"max\")\n",
    "\n",
    "    plt.axvspan( bins[max_count - 50], bins[max_count + 50], alpha = 0.5, color='r')\n",
    "    \n",
    "    if test:\n",
    "        plt.savefig('test_loss_dist_checkpoint_{}.png'.format(checkpoint_label), dpi=300)\n",
    "    else:\n",
    "        plt.savefig('train_loss_dist_checkpoint_{}.png'.format(checkpoint_label), dpi=300)\n",
    "\n",
    "    return bins[max_count - 50], bins[max_count + 50], [bins[-3], bins[-2], bins[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the loss value distribution\n",
    "- loss_hist returns two numbers corresponding to the bottom and top of the range of loss values to investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_min, test_max, test_top = loss_hist(test_losses, checkpoint_label, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_min, train_max, train_top = loss_hist(ref_train_losses, checkpoint_label, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a set of images that are in the high-loss and low-loss regions of the test and train distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low-High Loss Images for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_peak_test = []; loss_peak_reco = []\n",
    "high_loss_test = []; high_loss_reco = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, image in enumerate(test_loader):\n",
    "    \n",
    "    # Flatten image into a vector -- if mlp\n",
    "    if 'mlp' in exp_path:\n",
    "        image = image.view(loader_kwargs['batch_size'], -1).to(device)\n",
    "    else:\n",
    "        image = image.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(image)\n",
    "\n",
    "    # Get the loss value for the batch\n",
    "    loss = loss_fn(output, image)\n",
    "\n",
    "    # Grab samples that are within the limits given by the histogram\n",
    "    if loss > test_min and loss < test_max:\n",
    "        loss_peak_test.append(image.view(-1, im_dim, im_dim).detach().cpu().numpy())\n",
    "        loss_peak_reco.append(output.view(-1, im_dim, im_dim).detach().cpu().numpy())\n",
    "    \n",
    "    if loss >= min(test_top) and loss <= max(test_top):\n",
    "        high_loss_test.append(image.view(-1, im_dim, im_dim).detach().cpu().numpy())\n",
    "        high_loss_reco.append(output.view(-1, im_dim, im_dim).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Sample of images from loss peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup figure\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = limit//2, sharex=True, sharey=True, figsize=(25,6))\n",
    "\n",
    "# Set title\n",
    "if 'mlp' in exp_path:\n",
    "    m_label = 'AE'\n",
    "else:\n",
    "    m_label = 'Conv_AE'\n",
    "\n",
    "# Generate plot\n",
    "for images, row in zip([loss_peak_test[0:limit//2], loss_peak_reco[0:limit//2]], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        img = np.reshape(img, (im_dim, im_dim))\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        ax.tick_params(axis='x', colors='#443941')\n",
    "        ax.tick_params(axis='y', colors='#443941')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "save_file = \"{}_{}_{}.png\".format('test-loss-peak', im_dim, code)# code[0]*code[1]*code[2])\n",
    "plt.savefig(save_file, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the highest loss test image(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(high_loss_test), len(high_loss_reco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup figure\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 1, \n",
    "                         sharex=True, sharey=True, figsize=(25,6))\n",
    "\n",
    "# Set title\n",
    "if 'mlp' in exp_path:\n",
    "    m_label = 'AE'\n",
    "else:\n",
    "    m_label = 'Conv_AE'\n",
    "\n",
    "img = np.reshape(high_loss_test[0], (im_dim, im_dim))\n",
    "axes[0].imshow(img, cmap='gray')\n",
    "axes[0].get_xaxis().set_visible(False)\n",
    "axes[0].get_yaxis().set_visible(False)\n",
    "axes[0].tick_params(axis='x', colors='#443941')\n",
    "axes[0].tick_params(axis='y', colors='#443941')\n",
    "\n",
    "img = np.reshape(high_loss_reco[0], (im_dim, im_dim))\n",
    "axes[1].imshow(img, cmap='gray')\n",
    "axes[1].get_xaxis().set_visible(False)\n",
    "axes[1].get_yaxis().set_visible(False)\n",
    "axes[1].tick_params(axis='x', colors='#443941')\n",
    "axes[1].tick_params(axis='y', colors='#443941')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "save_file = \"{}_{}_{}.png\".format('test-highest-losses', im_dim, code) #code[0]*code[1]*code[2])\n",
    "plt.savefig(save_file, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low-High Loss Images for Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_peak_train = []; loss_peak_reco = []\n",
    "high_loss_train = []; high_loss_reco = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, image in enumerate(train_loader):\n",
    "    \n",
    "    # Flatten image into a vector -- if mlp\n",
    "    if 'mlp' in exp_path:\n",
    "        image = image.view(loader_kwargs['batch_size'], -1).to(device)\n",
    "    else:\n",
    "        image = image.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(image)\n",
    "\n",
    "    # Get the loss value for the batch\n",
    "    loss = loss_fn(output, image)\n",
    "\n",
    "    # Grab samples that are within the limits given by the histogram\n",
    "    if loss > train_min and loss < train_max:\n",
    "        loss_peak_train.append(image.view(-1, im_dim, im_dim).detach().cpu().numpy())\n",
    "        loss_peak_reco.append(output.view(-1, im_dim, im_dim).detach().cpu().numpy())\n",
    "    \n",
    "    if loss >= min(train_top) and loss <= max(train_top):\n",
    "        high_loss_train.append(image.view(-1, im_dim, im_dim).detach().cpu().numpy())\n",
    "        high_loss_reco.append(output.view(-1, im_dim, im_dim).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup figure\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = limit//2, sharex=True, sharey=True, figsize=(25,6))\n",
    "\n",
    "# Set title\n",
    "if 'mlp' in exp_path:\n",
    "    m_label = 'AE'\n",
    "else:\n",
    "    m_label = 'Conv_AE'\n",
    "\n",
    "# Generate plot\n",
    "for images, row in zip([loss_peak_train[0:limit//2], loss_peak_reco[0:limit//2]], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        img = np.reshape(img, (im_dim, im_dim))\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        ax.tick_params(axis='x', colors='#443941')\n",
    "        ax.tick_params(axis='y', colors='#443941')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "save_file = \"{}_{}_{}.png\".format('train-loss-peak', im_dim, code)# code[0]*code[1]*code[2])\n",
    "plt.savefig(save_file, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(high_loss_train), len(high_loss_reco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup figure\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 1, \n",
    "                         sharex=True, sharey=True, figsize=(25,6))\n",
    "\n",
    "# Set title\n",
    "if 'mlp' in exp_path:\n",
    "    m_label = 'AE'\n",
    "else:\n",
    "    m_label = 'Conv_AE'\n",
    "\n",
    "img = np.reshape(high_loss_train[0], (im_dim, im_dim))\n",
    "axes[0].imshow(img, cmap='gray')\n",
    "axes[0].get_xaxis().set_visible(False)\n",
    "axes[0].get_yaxis().set_visible(False)\n",
    "axes[0].tick_params(axis='x', colors='#443941')\n",
    "axes[0].tick_params(axis='y', colors='#443941')\n",
    "\n",
    "img = np.reshape(high_loss_reco[0], (im_dim, im_dim))\n",
    "axes[1].imshow(img, cmap='gray')\n",
    "axes[1].get_xaxis().set_visible(False)\n",
    "axes[1].get_yaxis().set_visible(False)\n",
    "axes[1].tick_params(axis='x', colors='#443941')\n",
    "axes[1].tick_params(axis='y', colors='#443941')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "save_file = \"{}_{}_{}.png\".format('train-highest-losses', im_dim, code)# code[0]*code[1]*code[2])\n",
    "plt.savefig(save_file, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Evaluation Results to exp. folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_file = exp_path + \"checkpoint_evaluation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_deltas = []\n",
    "std_deltas = []\n",
    "for i in range(len(test_means)):\n",
    "    mean_deltas.append( abs(test_means[i] - train_means[i]))\n",
    "    std_deltas.append( abs(test_stds[i] - train_stds[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'Test_Mean'      : test_means, \n",
    "           'Test_StdDev'    : test_stds, \n",
    "           'Train_Mean'     : train_means, \n",
    "           'Train_StdDev'   : train_stds,\n",
    "           'Mean_Deltas'    : mean_deltas,\n",
    "           'StdDev_Deltas' : std_deltas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results, index = checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(eval_file, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('checkpoint_eval.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = results.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
